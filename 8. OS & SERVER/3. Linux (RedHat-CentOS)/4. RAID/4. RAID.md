### RAID

#### RAID란

Redundant Array of Inexpensive Disks의 약자. 여러 개의 디스크를 배열하여 속도나 안정성, 효율을 높이고 백업이나 데이터 손실을 최소화 하기 위해 사용한다.



#### 단일 디스크 I/O

모든 데이터 조각(block 혹인 cluster로 표현)은 나뉘어져 다스크에 쓰여짐.

1번 조각이 디스크에 쓰여지고 있는 동안 나머지 조각들은 대기하고 있다 1번이 다 쓰여진 이후에 2번, 3번 순으로 쓰기가 이루어짐

![단일 디스크](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\단일 디스크.png)

#### RAID 구조에 따른 구성 방식

1. RAID 0  (Striping)

   - parity bit가 없이 striping 된 형태를 말한다. 최소 2개 이상의 디스크를 필요로 하며 데이터 중복은 없다. 최상의 성능을 제공하지만 내결함성은 제공하지 않는다.
- 장점: 데이터를 사용할 때 I/O를 디스크 수 만큼 분할하여 쓰기 때문에 I/O 속도가 향상
   - 단점: 스트라이프 구성 시 기존 데이터는 모두 삭제 되어야 한다.
- 최소 디스크 개수: 2
   - 용량: 디스크 수 * 디스크 용량

   ![RAID 0](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\RAID 0.PNG)

   ![Raid0](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\Raid0.PNG)

2. RAID1 (Mirroring)

   - Raid 0과는 달리 안정성에 중점. Raid 1은 하나의 데이터를 양쪽 디스크에 동일하게 기록함으로써 하나의 디스크에서 Fault가 발생해도 나머지 하나의 디스크를 통해 데이터에 접근 가능.
   - 일반적으로 서버에 있어 OS가 설치되는 디스크에 필수적으로 사용되는 구성방법
   - 장점: 높은 안정성, 일반적인 구성대비 읽기 성능에서 아주 조금 향상된 성능
   - 단점: 전체 디스크 용량에 비해 사용가능한 용량은 절반이 됨 (높은 비용)
   - 최소 디스크 개수: 2
   - 용량: (디스크 수 / 2) * 디스크 용량

   ![RAID 1](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\RAID 1.PNG)

   ![Raid1](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\Raid1.PNG)

3. RAID2

   - Raid 2는 Raid 0 처럼 스트라이핑 구성이지만 일부 디스크에는 오류 검사 및 수정을 위해 ECC(Error Correction Code)정보가 저장된다. Raid 3~4에 비해 이점이 없으며 현재는 더 이상 사용되지 않는다.

   ![Raid2](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\Raid2.PNG)

4. RAID3

   - 스트라이핑을 사용하고 하나의 드라이브에 패리티 정보를 저장하는데 사용. 내장 된 ECC 정보는 오류를 감지하는데 사용된다. 데이터 복구는 다른 드라이브에 기록 된 정보의 배타적 OR(XOR)를 계산하여 수행된다. 
   - I/O 작업은 동시에 모든 드라이브를 처리하므로 Raid 3은 I/O를 중첩할 수 없다. 
   - 이러한 이유로 Raid 3은 수행시간이 긴 응용프로그램이 있는 단일 사용자 시스템에 가장 적합
   - 최소 디스크 개수: 3
   - 용량: (디스크 수 -1) * 디스크 용량

   ![Raid3](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\Raid3.PNG)

   

5. RAID 4 (Parity)

   - Raid 0의 성능에 안정성을 결합한 방식.
   - 하나의 디스크를 Parity 전용 디스크로 사용. 전체 디스크가 N개로 구성되면 실제 사용가능한 디스크는 N-1개가 된다. 
   - RAID 5로 인해 잘 사용되지는 않지만 NetApp의 ![RAID 4](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\RAID 4.PNG)스토리지 구성에서 자주 사용.

   ![Raid4](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\Raid4.PNG)

   

6. RAID 5 (Distribute Parity bit)

   - RAID 4의 문제점인 병목현상을 해결한 레이드 구성, Parity bit을 하나의 디스크로 몰아놓은 것이 아닌 분산하여 구성하기 때문에 병목현상을 줄일 수 있다. 
   - RAID 4와 마찬가지로 N개의 디스크가 있으면 실제 사용 가능한 디스크는 N-1개가 된다.

   ![RAID 5](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\RAID 5.PNG)

   ![Raid5](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\Raid5.PNG)

7. RAID 6

   - RAID 6의 경우 Parity bit을 이용하여 어느정도의 안정성을 보장할 수 있다. 1개의 디스크 fault까지는 Parity를 이용하여 복구 가능.
   - 하지만 1개의 기스크가 손상된 후, 바로 또 하나의 디스크가 손상이 된다면 전체 디스크의 데이터를 사용할 수 없게 된다. 이에 하나의 디스크 하나의 디스크를 추가로 parity로 사용, 즉 parity bit을 두개의 디스크에 두어 안정성을 더욱 강화한 방법
   - 최소 디스크 개수 : 4개
   - 전체 디스크가 N개일 경우, 실제로 사용가능한 디스크는 N-2개가 된다.

   ![RAID6](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\RAID6.PNG)

8. RAID1 + 0 (RAID 1(내부) + 0(외부))

   - striping(RAID 0)의 성능과 mirriring(RAID 1)의 안정성을 갖는 방법

   ![Raid1+0](C:\Users\Youinguk\Desktop\Study_YIG\8. OS & SERVER\3. Linux (RedHat-CentOS)\4. RAID\Raid1+0.PNG)

9. Hardware RAID: 

   마이그레이션 (데이터 복구 업무)

   핫 스페어



#### RAID 0 구축

1. 하드 partition

   ```bash
   # fdisk /dev/sdc
   n
   p
   1
   enter
   enter
   t (Hex모드)
   L (Linux raid auto)
   // /dev/sdc1처럼 논리적으로 분할
   
   # fdisk /dev/sdd
   // /dev/sdd1처럼 논리적으로 분할
   ```

   

2. RAID 0 만들기

   ```bash
   # mdadm [-C , --create] [/dev/md0(만들 가상장치) ] [RAID level] [-raid-device=하드 수] [/dev/sdb  /dev/sdc(하드 이름)]
   
   # mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/sdc1 /dev/sdd1
   
   //그 외 자주 사용하는 명령어
   # mdadm --stop /dev/md0
   # mdadm --run /dev/md0
   # mdadm --detail /dev/md0
   # mdadm --remove /dev/md0
   (삭제 시 umount 명령어로 mount 해제부터)
   # man mdadm
   ```

   

3. md0 (가상 장치를 format)

   ```bash
   # mkfs.ext4 /dev/md0
   ```

4. mount

   ```bash
   # mkdir /RAIDmd0
   # mount /dev/md0 /RAIDmd0
   ```

5. autofs 부팅 시 유지 되게 fstab 설정

   ```bash
   # vi /etc/fstab
   /dev/md0	/RAIDmd0	ext4	defaults	1 2
   ```

6. `mdadm --detail` 명령어로 상태 확인

   ```bash
   # mdadm --detail /dev/md0
   ```

7. Reboot 하고 md0이 md127로 변하는 버그 발생 (장치의 이름이 변경 됬으므로)

   ```bash
   # format - mount - autofs 작업 다시
   ```

   

#### RAID 0 하드 하나 깨고 복구 확인

RAIDmd0 하드에 데이터 넣고 vm에서 하드 remove 해보기

// 하드 안의 data가 날라감



#### RAID 1 구축

```bash
1. 하드 partition (fdisk)
2. 가상 장치 생성 (mdadm)
3. 가상 장치 format (mkfs)
4. 가상 장치와 파일구조 연결 (mount)
5. autofs 설정 (vi /etc/fstab)
```



#### RAID 1 하드 하나 깨고 복구 확인

//RAIDmd1 하드에 데이터 넣고 vm에서 하드 remove

//하드 안의 data가 날라가지 않음 



#### RAID1 data 복구

```bash
1. 새로 추가 한 하드 partition (fdisk)
2. 추가 한 하드 바로 가상 장치에 붙이기(mdadm --manage로 data rebuilding)
# mdadm --manage /dev/md127 --add /dev/sdc1
```



### Reference

[RAID 구성] : https://dinggur.tistory.com/33

